{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "from pydub import AudioSegment as AS\n",
    "import librosa\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.core import power_to_db as ptdb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as op\n",
    "import torchvision.models as models\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion\n",
    "from keras.utils import to_categorical\n",
    "from albumentations import Normalize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences as pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKS = 1\n",
    "train_batch = 16\n",
    "default_input = 512\n",
    "drop = 0.2\n",
    "epochs = 2\n",
    "n_mels = 256\n",
    "mel_len = 1954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'C:\\Users\\jonat\\Desktop\\Career\\Springboard\\Capstone 3\\birdsong-recognition\\test.csv'\n",
    "train_path = r'C:\\Users\\jonat\\Desktop\\Career\\Springboard\\Capstone 3\\birdsong-recognition\\train.csv'\n",
    "test_audio_path = r'C:\\Users\\jonat\\Desktop\\Career\\Springboard\\Capstone 3\\birdsong-recognition\\example_test_audio/'\n",
    "train_audio_path = r'C:\\Users\\jonat\\Desktop\\Career\\Springboard\\Capstone 3\\birdsong-recognition\\train_audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\jonat\\Desktop\\Career\\Springboard\\Capstone 3\\birdsong-recognition\\mel spec images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('train_file_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = pd.read_csv(test_path)\n",
    "train_d = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set(train_d.ebird_code)\n",
    "values = np.arange(0,len(keys))\n",
    "dict_code = dict(zip(sorted(keys),values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = ['train_file_1','train_file_2']\n",
    "path_dict = {}\n",
    "for folder_path in tqdm(img_paths):\n",
    "    for img_path in os.listdir(folder_path):\n",
    "        path_dict[img_path] = folder_path + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_convert(data):\n",
    "    return [FloatTensor(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return np.float32(x)/2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.aug = Normalize(p=1)\n",
    "        self.code_dict = dict_code\n",
    "        self.classes = len(dict_code)\n",
    "        self.df, self.dataset_length = df, len(df)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file_name = self.df.filename[i]\n",
    "        image_name = file_name + '.jpg'\n",
    "        ebird_code = self.df.ebird_code[i]\n",
    "        num_code = self.code_dict[ebird_code]\n",
    "        image = cv2.imread(path_dict[image_name] + image_name)\n",
    "        code = to_categorical([num_code], num_classes=self.classes)\n",
    "        return tensor_convert([self.aug(image=image)['image'], np.repeat(code, CHUNKS, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trunc = train_d[:4275]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8*len(train_trunc))\n",
    "train_t = train_trunc.reset_index(drop=True)\n",
    "test_t = train_t[split:].reset_index(drop=True)\n",
    "train_t = train_t[:split].reset_index(drop=True)\n",
    "\n",
    "train_set = MelDataset(train_t)\n",
    "train_data = DataLoader(train_set,batch_size = 16, shuffle = True)\n",
    "test_set = MelDataset(test_t)\n",
    "test_loader = DataLoader(test_set, batch_size = 16)\n",
    "train_loader = DataLoader(train_set, batch_size = train_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_ids(tensor):\n",
    "    return shuffle(np.arange(len(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 kaggle resnet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,input,out):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=drop)\n",
    "        self.dense_output = nn.Linear(input,out)\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        self.resnet_head = list(self.resnet.children())\n",
    "        self.resnet_head = nn.Sequential(*self.resnet_head[:-1])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.resnet_head(x)\n",
    "        return self.dense_output(self.dropout(x.view(-1,F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 512\n",
    "LR = 1e-3, 1e-2\n",
    "keys_trunc = set(train_d.ebird_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ResNet(input=F,out=len(keys_trunc))\n",
    "optimizer = Adam([{'params': network.resnet.parameters(), 'learning rate': LR[0]},\n",
    "                  {'params': network.dense_output.parameters(), 'learning rate': LR[1]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y,y_pred):\n",
    "    y = torch.argmax(y,axis=-1)\n",
    "    return nn.CrossEntropyLoss()(y_pred,y.squeeze())\n",
    "\n",
    "def accuracy(y,y_pred):\n",
    "    y = torch.argmax(y,axis = -1).squeeze()\n",
    "    y_pred = torch.argmax(y_pred,axis = -1).squeeze()\n",
    "    return (y==y_pred).float().sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(data,batch,epoch,begin,end,metric,group):\n",
    "    t = group, metric,' ', data, ' '\n",
    "    if group == 'Train':\n",
    "        name = 'Batch ' + str(batch-1) + ' '\n",
    "    if group =='Test':\n",
    "        name = 'Epoch ' + str(epoch+1)\n",
    "    time = np.round(end - begin, 1)\n",
    "    time = 'Time: {} s'.format(time)\n",
    "    print(name + '{} {}: {}{}{}'.format(*t) + '  ' + time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (3,n_mels,mel_len)\n",
    "epochs = 5\n",
    "\n",
    "begin = time.time()\n",
    "print('Beginning Training ...\\n')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('EPOCH ' + str(epoch+1))\n",
    "    \n",
    "    batch = 1\n",
    "    network.train()\n",
    "    for mini_batch in train_loader:\n",
    "        train_X, train_y = mini_batch\n",
    "        train_y = train_y.view(-1,len(keys_trunc))\n",
    "        train_X = train_X.view(-1,*dim)\n",
    "        ids = shuffle_ids(train_X)\n",
    "        \n",
    "        train_X = train_X[ids].to(device)\n",
    "        train_y = train_y[ids].to(device)\n",
    "        train_pred = network.forward(train_X)\n",
    "        train_loss = cross_entropy(train_y,train_pred)\n",
    "        train_accuracy = accuracy(train_y,train_pred)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        end = time.time()\n",
    "        batch = batch + 1\n",
    "        to_print = batch%100==1\n",
    "        round_acc = np.round(train_accuracy.item(),3)\n",
    "        if to_print:\n",
    "            metrics(round_acc,batch,0,begin,end, 'Acc','Train')\n",
    "            \n",
    "    test_loss, test_points, test_accuracy = 0,0,0\n",
    "    \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for mini_batch in test_loader:\n",
    "            test_X, test_y = mini_batch\n",
    "            test_y = test_y.view(-1,len(keys_trunc))\n",
    "            test_X = test_X.view(-1,*dim)\n",
    "            ids = shuffle_ids(test_X)\n",
    "            \n",
    "            test_X = test_X[ids].to(device)\n",
    "            test_y = test_y[ids].to(device)\n",
    "            test_pred = network.forward(test_X)\n",
    "            test_points = test_points + len(test_y)\n",
    "            test_loss += cross_entropy(test_y,test_pred).item()*len(test_y)\n",
    "            test_accuracy += accuracy(test_y,test_pred).item()*len(test_y)\n",
    "    \n",
    "    end = time.time()\n",
    "    test_loss /= test_points\n",
    "    test_accuracy /= test_points\n",
    "    acc = np.round(test_accuracy,3)\n",
    "    metrics(acc,0,epoch,begin,end,'Acc','Test')\n",
    "    print('')\n",
    "    \n",
    "print('Ending Training Session...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This code is exponentially more expensive to run on cpu from a laptop compared to kaggle's gpu\n",
    "# As such I've run it on kaggle and will produce validation accuracy (with the complete dataset and 20 epochs instead of 5), separately in the write-up.\n",
    "# Unfortunately the overall accuracy stayed very low (<1%) which is disappointing even if it is an improvement over a guess (1/264)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchEnv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
